{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06897e83",
   "metadata": {},
   "source": [
    "üéØGoal  \n",
    "\n",
    "To become confident in core machine learning techniques and be able to give correct reasoning for my choices "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9e048f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "üõ†Ô∏èSetting up the enviorment  \n",
    "\n",
    "First, we import the necessary libraries.\n",
    "\n",
    "**scikit-learn**: for ml models  \n",
    "**Pandas & NumPy**: For data manipulation  \n",
    "**matplotlib**: For visulizationüìä  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a033387a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing required library\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2313f00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the csv\n",
    "heart = pd.read_csv(\"./data/heart.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ecf61d0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "      <td>212</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>168</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>203</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>145</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>125</td>\n",
       "      <td>1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>148</td>\n",
       "      <td>203</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>161</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>138</td>\n",
       "      <td>294</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>106</td>\n",
       "      <td>0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   52    1   0       125   212    0        1      168      0      1.0      2   \n",
       "1   53    1   0       140   203    1        0      155      1      3.1      0   \n",
       "2   70    1   0       145   174    0        1      125      1      2.6      0   \n",
       "3   61    1   0       148   203    0        1      161      0      0.0      2   \n",
       "4   62    0   0       138   294    1        1      106      0      1.9      1   \n",
       "\n",
       "   ca  thal  target  \n",
       "0   2     3       0  \n",
       "1   0     3       0  \n",
       "2   0     3       0  \n",
       "3   1     3       0  \n",
       "4   3     2       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#top values of dataset\n",
    "heart.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "717575f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1025, 14)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#shape of dataset\n",
    "heart.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aae85cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1025 entries, 0 to 1024\n",
      "Data columns (total 14 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       1025 non-null   int64  \n",
      " 1   sex       1025 non-null   int64  \n",
      " 2   cp        1025 non-null   int64  \n",
      " 3   trestbps  1025 non-null   int64  \n",
      " 4   chol      1025 non-null   int64  \n",
      " 5   fbs       1025 non-null   int64  \n",
      " 6   restecg   1025 non-null   int64  \n",
      " 7   thalach   1025 non-null   int64  \n",
      " 8   exang     1025 non-null   int64  \n",
      " 9   oldpeak   1025 non-null   float64\n",
      " 10  slope     1025 non-null   int64  \n",
      " 11  ca        1025 non-null   int64  \n",
      " 12  thal      1025 non-null   int64  \n",
      " 13  target    1025 non-null   int64  \n",
      "dtypes: float64(1), int64(13)\n",
      "memory usage: 112.2 KB\n"
     ]
    }
   ],
   "source": [
    "heart.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe0d74c",
   "metadata": {},
   "source": [
    "In the output of the above code we can see that there are no null or missing values so we dont have to handle them \n",
    "\n",
    "We also do not have any categorical value so we have no nned to encode it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b0691ff1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1025.000000</td>\n",
       "      <td>1025.000000</td>\n",
       "      <td>1025.000000</td>\n",
       "      <td>1025.000000</td>\n",
       "      <td>1025.00000</td>\n",
       "      <td>1025.000000</td>\n",
       "      <td>1025.000000</td>\n",
       "      <td>1025.000000</td>\n",
       "      <td>1025.000000</td>\n",
       "      <td>1025.000000</td>\n",
       "      <td>1025.000000</td>\n",
       "      <td>1025.000000</td>\n",
       "      <td>1025.000000</td>\n",
       "      <td>1025.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>54.434146</td>\n",
       "      <td>0.695610</td>\n",
       "      <td>0.942439</td>\n",
       "      <td>131.611707</td>\n",
       "      <td>246.00000</td>\n",
       "      <td>0.149268</td>\n",
       "      <td>0.529756</td>\n",
       "      <td>149.114146</td>\n",
       "      <td>0.336585</td>\n",
       "      <td>1.071512</td>\n",
       "      <td>1.385366</td>\n",
       "      <td>0.754146</td>\n",
       "      <td>2.323902</td>\n",
       "      <td>0.513171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.072290</td>\n",
       "      <td>0.460373</td>\n",
       "      <td>1.029641</td>\n",
       "      <td>17.516718</td>\n",
       "      <td>51.59251</td>\n",
       "      <td>0.356527</td>\n",
       "      <td>0.527878</td>\n",
       "      <td>23.005724</td>\n",
       "      <td>0.472772</td>\n",
       "      <td>1.175053</td>\n",
       "      <td>0.617755</td>\n",
       "      <td>1.030798</td>\n",
       "      <td>0.620660</td>\n",
       "      <td>0.500070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>126.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>211.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>132.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>56.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>240.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>152.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>61.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>275.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>77.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>564.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               age          sex           cp     trestbps        chol  \\\n",
       "count  1025.000000  1025.000000  1025.000000  1025.000000  1025.00000   \n",
       "mean     54.434146     0.695610     0.942439   131.611707   246.00000   \n",
       "std       9.072290     0.460373     1.029641    17.516718    51.59251   \n",
       "min      29.000000     0.000000     0.000000    94.000000   126.00000   \n",
       "25%      48.000000     0.000000     0.000000   120.000000   211.00000   \n",
       "50%      56.000000     1.000000     1.000000   130.000000   240.00000   \n",
       "75%      61.000000     1.000000     2.000000   140.000000   275.00000   \n",
       "max      77.000000     1.000000     3.000000   200.000000   564.00000   \n",
       "\n",
       "               fbs      restecg      thalach        exang      oldpeak  \\\n",
       "count  1025.000000  1025.000000  1025.000000  1025.000000  1025.000000   \n",
       "mean      0.149268     0.529756   149.114146     0.336585     1.071512   \n",
       "std       0.356527     0.527878    23.005724     0.472772     1.175053   \n",
       "min       0.000000     0.000000    71.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000   132.000000     0.000000     0.000000   \n",
       "50%       0.000000     1.000000   152.000000     0.000000     0.800000   \n",
       "75%       0.000000     1.000000   166.000000     1.000000     1.800000   \n",
       "max       1.000000     2.000000   202.000000     1.000000     6.200000   \n",
       "\n",
       "             slope           ca         thal       target  \n",
       "count  1025.000000  1025.000000  1025.000000  1025.000000  \n",
       "mean      1.385366     0.754146     2.323902     0.513171  \n",
       "std       0.617755     1.030798     0.620660     0.500070  \n",
       "min       0.000000     0.000000     0.000000     0.000000  \n",
       "25%       1.000000     0.000000     2.000000     0.000000  \n",
       "50%       1.000000     0.000000     2.000000     1.000000  \n",
       "75%       2.000000     1.000000     3.000000     1.000000  \n",
       "max       2.000000     4.000000     3.000000     1.000000  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heart.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938d2a87",
   "metadata": {},
   "source": [
    "What does this dataset represent??  \n",
    "\n",
    "This data set dates from 1988 and consists of four databases: Cleveland, Hungary, Switzerland, and Long Beach V. It contains 76 attributes, including the predicted attribute, but all published experiments refer to using a subset of 14 of them. The \"target\" field refers to the presence of heart disease in the patient. It is integer valued 0 = no disease and 1 = disease.  \n",
    "\n",
    "- In the age column 1 = male and 0 = female\n",
    "- cp stands for chest pain type (4 values)\n",
    "- trestbps means resting blood pressure (in mm Hg on admission to the hospital)\n",
    "- chol is the serum cholestoral in mg/dl\n",
    "- fbs stands for fasting blood sugar &gt; 120 mg/dl (1 = true; 0 = false)\n",
    "- restecg means resting electrocardiographic results\n",
    "- thalach is the maximum heart rate achieved\n",
    "- exang is exercise induced angina (1 = yes; 0 = no)\n",
    "- oldpeak = ST depression induced by exercise relative to rest\n",
    "- slope is the slope of the peak exercise ST segment\n",
    "- ca is the number of major vessels (0-3) colored by flourosopy\n",
    "- thal: 0 = normal; 1 = fixed defect; 2 = reversable defect\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e319ecdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#spliting features\n",
    "X = heart.drop('target', axis=1)\n",
    "Y = heart['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12d0140d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating train and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X,Y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=Y\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74754873",
   "metadata": {},
   "source": [
    "random_state = sets a fixed random seed which gurantees the same split everytime the code is executed  \n",
    "\n",
    "stratify = this defines that both traning and test set have smae class distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19db52cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic regression model\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_model = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', LogisticRegression(\n",
    "        max_iter=2000,\n",
    "        solver='lbfgs'\n",
    "    ))\n",
    "])\n",
    "\n",
    "log_model.fit(X_train, Y_train)\n",
    "log_preds = log_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc22a38",
   "metadata": {},
   "source": [
    "Logistic regression is Scale-sensitive and hence we had to scale the columns like age, chol, trestbps, etc..  \n",
    "\n",
    "The reason to use pipline instead of not doing the scaling manually is that pipeline is safer, cleaner, and less error-prone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962406ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision Tree Model\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "dt_model.fit(X_train, Y_train)\n",
    "\n",
    "dt_preds = dt_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "441b0860",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random forest model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    random_state=42\n",
    ")\n",
    "rf_model.fit(X_train, Y_train)\n",
    "\n",
    "rf_preds = rf_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822bb816",
   "metadata": {},
   "source": [
    "In our random forest we have 200 trees, which is reasonable for our task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ad8b5c",
   "metadata": {},
   "source": [
    "Model Evaluation  \n",
    "\n",
    "After traing the models, their performance is measured on unseen test data.  \n",
    "All models are evaluated using same test set and the same metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5e5ef0",
   "metadata": {},
   "source": [
    "Evaluation metric used  \n",
    "\n",
    "1. Accuracy  \n",
    "\n",
    "Accuracy measures the proportion of correct predictions  \n",
    "$$\n",
    "Accuracy=\\frac{Correct Predictions}{Total Predictions}\n",
    "$$\n",
    "It provides a quick overall performance measure  \n",
    "<br>\n",
    "<br>\n",
    "\n",
    "2. Confusion Matrix  \n",
    "\n",
    "The confusion matrix shows:\n",
    "- True Positives\n",
    "- True Negatives\n",
    "- False Positives\n",
    "- False Negatives\n",
    "\n",
    "This helps understand where the model makes mistakes, which is especially important in medical classification tasks.\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "3. Precison and Recall\n",
    "\n",
    "Since this is a classification problem, precision and recall are used.\n",
    "- **Precision**: How many predicted positives are actually correct\n",
    "- **Recall**: How many actual positives are correctly identified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "77b1baf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.8097560975609757\n",
      "Confusion Matrix:\n",
      " [[70 30]\n",
      " [ 9 96]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.70      0.78       100\n",
      "           1       0.76      0.91      0.83       105\n",
      "\n",
      "    accuracy                           0.81       205\n",
      "   macro avg       0.82      0.81      0.81       205\n",
      "weighted avg       0.82      0.81      0.81       205\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "log_accuracy = accuracy_score(Y_test, log_preds)\n",
    "log_cm = confusion_matrix(Y_test, log_preds)\n",
    "\n",
    "print(\"Logistic Regression Accuracy:\", log_accuracy)\n",
    "print(\"Confusion Matrix:\\n\", log_cm)\n",
    "print(classification_report(Y_test, log_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "421c9909",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy: 0.9853658536585366\n",
      "Confusion Matrix:\n",
      " [[100   0]\n",
      " [  3 102]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99       100\n",
      "           1       1.00      0.97      0.99       105\n",
      "\n",
      "    accuracy                           0.99       205\n",
      "   macro avg       0.99      0.99      0.99       205\n",
      "weighted avg       0.99      0.99      0.99       205\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree\n",
    "dt_accuracy = accuracy_score(Y_test, dt_preds)\n",
    "dt_cm = confusion_matrix(Y_test, dt_preds)\n",
    "\n",
    "print(\"Decision Tree Accuracy:\", dt_accuracy)\n",
    "print(\"Confusion Matrix:\\n\", dt_cm)\n",
    "print(classification_report(Y_test, dt_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ea7139c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 1.0\n",
      "Confusion Matrix:\n",
      " [[100   0]\n",
      " [  0 105]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       100\n",
      "           1       1.00      1.00      1.00       105\n",
      "\n",
      "    accuracy                           1.00       205\n",
      "   macro avg       1.00      1.00      1.00       205\n",
      "weighted avg       1.00      1.00      1.00       205\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Random Forest\n",
    "rf_accuracy= accuracy_score(Y_test, rf_preds)\n",
    "rf_cm = confusion_matrix(Y_test, rf_preds)\n",
    "\n",
    "print(\"Random Forest Accuracy:\", rf_accuracy)\n",
    "print(\"Confusion Matrix:\\n\", rf_cm)\n",
    "print(classification_report(Y_test, rf_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3932eebf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.809756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.985366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Accuracy\n",
       "0  Logistic Regression  0.809756\n",
       "1        Decision Tree  0.985366\n",
       "2        Random Forest  1.000000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model Comparison Table\n",
    "import pandas as pd\n",
    "\n",
    "comparison_table = pd.DataFrame({\n",
    "    'Model': ['Logistic Regression', 'Decision Tree', 'Random Forest'],\n",
    "    'Accuracy': [log_accuracy, dt_accuracy, rf_accuracy]\n",
    "})\n",
    "\n",
    "comparison_table\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fdf159f",
   "metadata": {},
   "source": [
    "Analysis  \n",
    "\n",
    "\n",
    "Which model performed best?  \n",
    "- The Random Forest model performed the best among the three models, as it achieved 100% accuracy, precision, and recall, indicating perfect classification on the dataset. \n",
    "- Logistic Regression was the weakest model, as it exhibited a low recall (70%), meaning it missed a significant number of positive cases (high false negatives).\n",
    "- The Decision Tree also performed strongly, achieving 100% recall and only a small number of false positives, resulting in high overall performance, though not as perfect as the Random Forest.\n",
    "\n",
    "\n",
    "Why do you think that happened?\n",
    "- Logistic regression performed the worst because it assumes a liner relationship between features and outcome. If the true relationship is non-linear the linear regression struggles, leading to missed postives cases.\n",
    "- Random forest perforemed perfectly because its an ensemble method that combines many decision tree(200 in our case). Then averages their predictions which reduces overfitting and varience, casuing it to easily capture non-linear relation with complex boundries. Since the data is clean and small the model had a perfect performance.\n",
    "- Decision tree also performed very well as tree can easily fit to complex decison boundries and learn from traning patterns. However, a sing tree is prone to overfiiting and hence few false positives compared to random forest.\n",
    "\n",
    "\n",
    "Did any model overfit?\n",
    "- Yes the random forest shows perfect performance which indicates overfitting or data leakage.\n",
    "\n",
    "What would you try next?\n",
    "- Training with a larget dataset or applying cross-validation to current models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
